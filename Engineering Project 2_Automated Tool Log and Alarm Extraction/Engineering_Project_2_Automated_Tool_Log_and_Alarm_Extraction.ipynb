{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7jWWIjA0lKl",
        "outputId": "1a5ebb2a-74e5-43a1-9236-8a0c1ef835ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 5 sample CSVs in: /content/project6_logs\n",
            "\n",
            "Total rows: 125\n",
            "Number of alarm rows (alarm=1): 18\n",
            "\n",
            "Rows with alarms present:\n",
            "          timestamp tool_run_id  RF_power_W  ChamberPressure_mTorr     Temp_C  alarm  RF_power_W_ALARM  ChamberPressure_mTorr_ALARM  Temp_C_ALARM     source_file\n",
            "2026-01-01 08:16:00      RUN_01  757.855396              29.280000  83.860000      1                 1                            0             0 tool_log_01.csv\n",
            "2026-01-01 08:20:00      RUN_01  550.000000              55.240591  80.570000      1                 0                            1             0 tool_log_01.csv\n",
            "2026-01-01 08:34:00      RUN_01  609.900000              29.540000 126.050243      1                 0                            0             1 tool_log_01.csv\n",
            "2026-01-01 08:40:00      RUN_01  732.100000              80.166929 102.970000      1                 0                            1             0 tool_log_01.csv\n",
            "2026-01-01 08:46:00      RUN_01  762.300000              27.160000 102.260000      1                 1                            0             0 tool_log_01.csv\n",
            "2026-01-01 08:02:00      RUN_02  689.200000              46.670000 143.295649      1                 0                            1             1 tool_log_02.csv\n",
            "2026-01-01 08:04:00      RUN_02  765.409951              11.210000  78.270000      1                 1                            0             0 tool_log_02.csv\n",
            "2026-01-01 08:40:00      RUN_02  580.100000               8.620000 111.220000      1                 0                            0             1 tool_log_02.csv\n",
            "2026-01-01 08:08:00      RUN_03  758.675392              29.490000  67.700000      1                 1                            0             0 tool_log_03.csv\n",
            "2026-01-01 08:32:00      RUN_03  638.100000              61.258173  90.710000      1                 0                            1             0 tool_log_03.csv\n",
            "2026-01-01 08:46:00      RUN_03  775.860908               9.710000 105.880000      1                 1                            0             0 tool_log_03.csv\n",
            "2026-01-01 08:14:00      RUN_04  601.400000              31.610000 145.908765      1                 0                            0             1 tool_log_04.csv\n",
            "2026-01-01 08:24:00      RUN_04  769.894289              15.560000  70.640000      1                 1                            0             0 tool_log_04.csv\n",
            "2026-01-01 08:10:00      RUN_05  624.800000              81.762430  87.750000      1                 0                            1             0 tool_log_05.csv\n",
            "2026-01-01 08:16:00      RUN_05  828.900000              16.480000  85.950000      1                 1                            0             0 tool_log_05.csv\n",
            "2026-01-01 08:34:00      RUN_05  595.700000              46.110000 124.914993      1                 0                            1             1 tool_log_05.csv\n",
            "2026-01-01 08:36:00      RUN_05  468.700000              40.860000 112.536934      1                 0                            0             1 tool_log_05.csv\n",
            "2026-01-01 08:40:00      RUN_05  787.401340               6.670000  84.800000      1                 1                            0             0 tool_log_05.csv\n",
            "\n",
            "Saved merged logs: /content/project6_output/merged_logs.csv\n",
            "Saved alarm list:  /content/project6_output/alarm.xlsx\n",
            "\n",
            "In Colab: left sidebar → Files → project6_output → download alarm.xlsx\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Project 6 — Tool Log CSV Extractor + Threshold Flagging (Colab-ready)\n",
        "# What it does:\n",
        "# 1) Generates 5 sample CSV log files (each has 3 process parameters)\n",
        "# 2) Loads all CSVs into one concatenated pandas DataFrame\n",
        "# 3) Flags cells where value > threshold (creates *_ALARM columns)\n",
        "# 4) Adds \"alarm\" column: 1 if ANY parameter exceeds threshold in a row, else 0\n",
        "# 5) Prints number of alarm rows + prints the alarm rows\n",
        "# 6) Saves alarm rows into alarm.xlsx (alarm cells highlighted)\n",
        "#    and also saves merged_logs.csv\n",
        "# ============================================================\n",
        "\n",
        "# ----------------------------\n",
        "# 0) Install dependencies\n",
        "# ----------------------------\n",
        "!pip -q install pandas numpy openpyxl\n",
        "\n",
        "import os, glob, random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import PatternFill\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "# ----------------------------\n",
        "# 1) CONFIG (edit as needed)\n",
        "# ----------------------------\n",
        "BASE_DIR = \"/content/project6_logs\"      # where CSV logs live\n",
        "OUT_DIR  = \"/content/project6_output\"   # outputs (merged + alarm.xlsx)\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "N_FILES = 5\n",
        "ROWS_PER_FILE = 25\n",
        "\n",
        "# Exactly 3 process parameter columns\n",
        "PARAM_COLS = [\"RF_power_W\", \"ChamberPressure_mTorr\", \"Temp_C\"]\n",
        "\n",
        "# Flag if value > threshold\n",
        "THRESHOLDS = {\n",
        "    \"RF_power_W\": 750,\n",
        "    \"ChamberPressure_mTorr\": 45,\n",
        "    \"Temp_C\": 110,\n",
        "}\n",
        "\n",
        "RNG_SEED = 7\n",
        "np.random.seed(RNG_SEED)\n",
        "random.seed(RNG_SEED)\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Generate 5 sample CSV log files\n",
        "# ----------------------------\n",
        "def generate_sample_csvs(base_dir: str, n_files: int = 5, rows_per_file: int = 25):\n",
        "    start_time = datetime(2026, 1, 1, 8, 0, 0)\n",
        "    paths = []\n",
        "\n",
        "    for i in range(n_files):\n",
        "        ts = [start_time + timedelta(minutes=2*j) for j in range(rows_per_file)]\n",
        "        df = pd.DataFrame({\n",
        "            \"timestamp\": ts,\n",
        "            \"tool_run_id\": [f\"RUN_{i+1:02d}\"] * rows_per_file,\n",
        "            # baselines + noise\n",
        "            \"RF_power_W\": np.random.normal(loc=600, scale=80, size=rows_per_file).round(1),\n",
        "            \"ChamberPressure_mTorr\": np.random.normal(loc=25, scale=8, size=rows_per_file).round(2),\n",
        "            \"Temp_C\": np.random.normal(loc=85, scale=12, size=rows_per_file).round(2),\n",
        "        })\n",
        "\n",
        "        # Inject a few above-threshold events per file\n",
        "        for _ in range(np.random.randint(2, 5)):\n",
        "            r = np.random.randint(0, rows_per_file)\n",
        "            col = np.random.choice(PARAM_COLS)\n",
        "            df.loc[r, col] = float(THRESHOLDS[col]) + float(np.random.uniform(1, 40))\n",
        "\n",
        "        path = os.path.join(base_dir, f\"tool_log_{i+1:02d}.csv\")\n",
        "        df.to_csv(path, index=False)\n",
        "        paths.append(path)\n",
        "\n",
        "    print(f\"Generated {n_files} sample CSVs in: {base_dir}\")\n",
        "    return paths\n",
        "\n",
        "# Always generate sample files (keeping everything the same)\n",
        "_ = generate_sample_csvs(BASE_DIR, N_FILES, ROWS_PER_FILE)\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Load CSVs into one concatenated DataFrame\n",
        "# ----------------------------\n",
        "csv_files = sorted(glob.glob(os.path.join(BASE_DIR, \"*.csv\")))\n",
        "if not csv_files:\n",
        "    raise FileNotFoundError(f\"No CSV files found in {BASE_DIR}\")\n",
        "\n",
        "dfs = []\n",
        "for f in csv_files:\n",
        "    d = pd.read_csv(f)\n",
        "    d[\"source_file\"] = os.path.basename(f)\n",
        "    dfs.append(d)\n",
        "\n",
        "logs = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Flag cells above thresholds + add alarm column\n",
        "# ----------------------------\n",
        "for col, thr in THRESHOLDS.items():\n",
        "    logs[f\"{col}_ALARM\"] = (logs[col] > thr).astype(int)\n",
        "\n",
        "alarm_flag_cols = [f\"{c}_ALARM\" for c in THRESHOLDS.keys()]\n",
        "logs[\"alarm\"] = (logs[alarm_flag_cols].sum(axis=1) > 0).astype(int)\n",
        "\n",
        "alarms_df = logs[logs[\"alarm\"] == 1].copy()\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Print summary + alarm rows\n",
        "# ----------------------------\n",
        "num_alarm_rows = int(logs[\"alarm\"].sum())\n",
        "print(f\"\\nTotal rows: {len(logs)}\")\n",
        "print(f\"Number of alarm rows (alarm=1): {num_alarm_rows}\\n\")\n",
        "\n",
        "display_cols = [\"timestamp\", \"tool_run_id\"] + PARAM_COLS + [\"alarm\"] + alarm_flag_cols + [\"source_file\"]\n",
        "\n",
        "if num_alarm_rows > 0:\n",
        "    print(\"Rows with alarms present:\")\n",
        "    print(alarms_df[display_cols].to_string(index=False))\n",
        "else:\n",
        "    print(\"No alarms found.\")\n",
        "\n",
        "# ----------------------------\n",
        "# 6) Save alarm list to alarm.xlsx with highlighted alarm cells\n",
        "# ----------------------------\n",
        "alarm_xlsx_path = os.path.join(OUT_DIR, \"alarm.xlsx\")\n",
        "merged_csv_path = os.path.join(OUT_DIR, \"merged_logs.csv\")\n",
        "\n",
        "# Save merged logs\n",
        "logs.to_csv(merged_csv_path, index=False)\n",
        "\n",
        "# Create Excel file\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Alarms\"\n",
        "\n",
        "export_df = alarms_df[display_cols].reset_index(drop=True)\n",
        "\n",
        "# Write header + rows\n",
        "for row in dataframe_to_rows(export_df, index=False, header=True):\n",
        "    ws.append(row)\n",
        "\n",
        "# Highlight cells where the value is above threshold\n",
        "fill_red = PatternFill(start_color=\"FFFF6666\", end_color=\"FFFF6666\", fill_type=\"solid\")\n",
        "\n",
        "# Map header names to Excel column indices\n",
        "header_cells = list(ws[1])\n",
        "col_to_idx = {cell.value: idx for idx, cell in enumerate(header_cells, start=1)}\n",
        "\n",
        "for r in range(2, ws.max_row + 1):\n",
        "    for col, thr in THRESHOLDS.items():\n",
        "        cidx = col_to_idx[col]\n",
        "        val = ws.cell(row=r, column=cidx).value\n",
        "        try:\n",
        "            if float(val) > thr:\n",
        "                ws.cell(row=r, column=cidx).fill = fill_red\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# Simple auto-width\n",
        "for col_cells in ws.columns:\n",
        "    max_len = 0\n",
        "    col_letter = col_cells[0].column_letter\n",
        "    for cell in col_cells:\n",
        "        v = \"\" if cell.value is None else str(cell.value)\n",
        "        max_len = max(max_len, len(v))\n",
        "    ws.column_dimensions[col_letter].width = min(max_len + 2, 45)\n",
        "\n",
        "wb.save(alarm_xlsx_path)\n",
        "\n",
        "print(f\"\\nSaved merged logs: {merged_csv_path}\")\n",
        "print(f\"Saved alarm list:  {alarm_xlsx_path}\")\n",
        "print(\"\\nIn Colab: left sidebar → Files → project6_output → download alarm.xlsx\")"
      ]
    }
  ]
}